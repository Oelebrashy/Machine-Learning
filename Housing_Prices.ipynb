{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsFEOdwGPj5NaQmT+e3OVG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Oelebrashy/Machine-Learning/blob/main/Housing_Prices.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import necessary libraries\n",
        "!pip install category_encoders\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from category_encoders import TargetEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Load the datasets\n",
        "train_path = '/content/drive/My Drive/House Prices-Advanced Regression Techniques/train.csv'\n",
        "test_path = '/content/drive/My Drive/House Prices-Advanced Regression Techniques/test.csv'\n",
        "data_description_path = '/content/drive/My Drive/House Prices-Advanced Regression Techniques/data_description.txt'\n",
        "\n",
        "train = pd.read_csv(train_path)\n",
        "test = pd.read_csv(test_path)\n",
        "\n",
        "# Preserve the target variable 'SalePrice' and the 'Id' column before encoding\n",
        "train_id = train['Id']\n",
        "train_target = train['SalePrice']\n",
        "test_id = test['Id']\n",
        "\n",
        "# Display the first few rows of the training dataset\n",
        "print(\"Training Data:\")\n",
        "print(train.head())\n",
        "\n",
        "print(\"\\nTest Data:\")\n",
        "print(test.head())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values in training set:\")\n",
        "print(train.isnull().sum()[train.isnull().sum() > 0])\n",
        "\n",
        "print(\"\\nMissing values in test set:\")\n",
        "print(test.isnull().sum()[test.isnull().sum() > 0])\n",
        "\n",
        "# Data description\n",
        "with open(data_description_path, 'r') as file:\n",
        "    data_description = file.read()\n",
        "\n",
        "print(\"\\nData Description:\")\n",
        "print(data_description)\n",
        "\n",
        "# Initial data visualization\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(train['SalePrice'], kde=True)\n",
        "plt.title('Distribution of Sale Prices')\n",
        "plt.xlabel('SalePrice')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# Display the data types of each column\n",
        "print(\"\\nData Types in Training Set:\")\n",
        "print(train.dtypes)"
      ],
      "metadata": {
        "id": "Y5Vy2eeopPPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values for categorical features\n",
        "cat_fill_values = {\n",
        "    'Alley': 'None', 'MasVnrType': 'None', 'BsmtQual': 'NA', 'BsmtCond': 'NA',\n",
        "    'BsmtExposure': 'NA', 'BsmtFinType1': 'NA', 'BsmtFinType2': 'NA', 'Electrical': train['Electrical'].mode()[0],\n",
        "    'FireplaceQu': 'NA', 'GarageType': 'NA', 'GarageFinish': 'NA', 'GarageQual': 'NA',\n",
        "    'GarageCond': 'NA', 'PoolQC': 'NA', 'Fence': 'NA', 'MiscFeature': 'None'\n",
        "}\n",
        "\n",
        "train.fillna(cat_fill_values, inplace=True)\n",
        "test.fillna(cat_fill_values, inplace=True)\n",
        "\n",
        "# Fill missing values for numerical features\n",
        "train['LotFrontage'] = train.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
        "train.fillna({'MasVnrArea': 0, 'GarageYrBlt': train['YearBuilt'], 'BsmtFinSF1': 0, 'BsmtFinSF2': 0,\n",
        "              'BsmtUnfSF': 0, 'TotalBsmtSF': 0, 'BsmtFullBath': 0, 'BsmtHalfBath': 0,\n",
        "              'GarageCars': 0, 'GarageArea': 0}, inplace=True)\n",
        "\n",
        "test['LotFrontage'] = test.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
        "test.fillna({'MasVnrArea': 0, 'GarageYrBlt': test['YearBuilt'], 'BsmtFinSF1': 0, 'BsmtFinSF2': 0,\n",
        "             'BsmtUnfSF': 0, 'TotalBsmtSF': 0, 'BsmtFullBath': 0, 'BsmtHalfBath': 0,\n",
        "             'GarageCars': 0, 'GarageArea': 0}, inplace=True)\n",
        "\n",
        "# Feature Engineering\n",
        "new_features = {\n",
        "    'TotalSF': lambda df: df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF'],\n",
        "    'Age': lambda df: df['YrSold'] - df['YearBuilt'],\n",
        "    'Remodeled': lambda df: (df['YearRemodAdd'] != df['YearBuilt']).astype(int),\n",
        "    'TotalBath': lambda df: df['BsmtFullBath'] + 0.5 * df['BsmtHalfBath'] + df['FullBath'] + 0.5 * df['HalfBath'],\n",
        "    'OverallQual_GrLivArea': lambda df: df['OverallQual'] * df['GrLivArea'],\n",
        "    'IsNew': lambda df: (df['YearBuilt'] > 2000).astype(int),\n",
        "    'HighQuality': lambda df: (df['OverallQual'] >= 7).astype(int),\n",
        "    'YearsSinceRemodel': lambda df: df['YrSold'] - df['YearRemodAdd'],\n",
        "    'SaleMonth': lambda df: df['MoSold'],\n",
        "    'HasPool': lambda df: (df['PoolArea'] > 0).astype(int),\n",
        "    'HasFireplace': lambda df: (df['Fireplaces'] > 0).astype(int),\n",
        "    'HasGarage': lambda df: (df['GarageArea'] > 0).astype(int),\n",
        "    'OverallScore': lambda df: df['OverallQual'] + df['OverallCond'],\n",
        "    'BasementScore': lambda df: df['BsmtQual'].replace({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0}) + df['BsmtCond'].replace({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0}),\n",
        "    'GarageScore': lambda df: df['GarageQual'].replace({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0}) + df['GarageCond'].replace({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0})\n",
        "}\n",
        "\n",
        "for feature, func in new_features.items():\n",
        "    train[feature] = func(train)\n",
        "    test[feature] = func(test)\n",
        "\n",
        "# Separate the target variable\n",
        "train_target = train['SalePrice']\n",
        "train_features = train.drop(['SalePrice'], axis=1)\n",
        "\n",
        "# Encode features for modeling\n",
        "cat_features = ['MSZoning', 'Neighborhood', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual',\n",
        "                'Foundation', 'BsmtQual', 'BsmtExposure', 'HeatingQC', 'KitchenQual', 'GarageType',\n",
        "                'GarageFinish', 'SaleType', 'SaleCondition']\n",
        "\n",
        "encoder = TargetEncoder(cols=cat_features)\n",
        "train_encoded = encoder.fit_transform(train_features, train_target)\n",
        "test_encoded = encoder.transform(test)\n",
        "\n",
        "# Ensure 'SalePrice' is in train_encoded after alignment\n",
        "train_encoded['SalePrice'] = train_target\n",
        "\n",
        "# Align the train and test datasets to have the same columns\n",
        "train_encoded, test_encoded = train_encoded.align(test_encoded, join='inner', axis=1)\n",
        "\n",
        "# Add back 'SalePrice' if it was dropped during alignment\n",
        "if 'SalePrice' not in train_encoded.columns:\n",
        "    train_encoded['SalePrice'] = train_target\n",
        "\n",
        "# Verify if all features are numerical\n",
        "train_encoded = pd.get_dummies(train_encoded, drop_first=True)\n",
        "test_encoded = pd.get_dummies(test_encoded, drop_first=True)\n",
        "\n",
        "# Align the datasets again to ensure same columns\n",
        "train_encoded, test_encoded = train_encoded.align(test_encoded, join='inner', axis=1)\n",
        "train_encoded['SalePrice'] = train_target\n",
        "\n",
        "# Model-based feature importance\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(train_encoded.drop('SalePrice', axis=1), train_encoded['SalePrice'])\n",
        "\n",
        "feature_importances = pd.Series(model.feature_importances_, index=train_encoded.drop('SalePrice', axis=1).columns)\n",
        "top_features = feature_importances.nlargest(20).index.tolist()\n",
        "print(f'Top Features: {top_features}')\n",
        "\n",
        "# Recursive Feature Elimination (RFE)\n",
        "rfe = RFE(estimator=model, n_features_to_select=20)\n",
        "rfe.fit(train_encoded.drop('SalePrice', axis=1), train_encoded['SalePrice'])\n",
        "\n",
        "rfe_features = train_encoded.drop('SalePrice', axis=1).columns[rfe.support_].tolist()\n",
        "print(f'RFE Selected Features: {rfe_features}')\n",
        "\n",
        "# Combine features from model importance and RFE\n",
        "combined_features = list(set(top_features).union(set(rfe_features)))\n",
        "\n",
        "# Use these features for model training\n",
        "X_train = train_encoded[combined_features]\n",
        "y_train = train_encoded['SalePrice']\n",
        "X_test = test_encoded[combined_features]\n",
        "\n",
        "# Train the model\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "xg_reg = XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
        "xg_reg.fit(X_train, y_train)\n",
        "\n",
        "y_pred_xg = xg_reg.predict(X_val)\n",
        "rmse_xg = np.sqrt(mean_squared_error(y_val, y_pred_xg))\n",
        "print(f'RMSE (XGBoost): {rmse_xg}')\n",
        "\n",
        "# Linear Regression\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train, y_train)\n",
        "y_pred = lin_reg.predict(X_val)\n",
        "rmse_lin = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "print(f'RMSE (Linear Regression): {rmse_lin}')\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_val)\n",
        "rmse_rf = np.sqrt(mean_squared_error(y_val, y_pred_rf))\n",
        "print(f'RMSE (Random Forest): {rmse_rf}')\n",
        "\n",
        "# Hyperparameter Tuning for Gradient Boosting using Grid Search\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.3]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=XGBRegressor(objective='reg:squarederror'), param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred_best = best_model.predict(X_val)\n",
        "rmse_best = np.sqrt(mean_squared_error(y_val, y_pred_best))\n",
        "print(f'Best RMSE: {rmse_best}')\n",
        "\n",
        "# Predict on the test dataset using the best model\n",
        "final_predictions = best_model.predict(X_test)\n",
        "\n",
        "# Prepare the submission file\n",
        "submission = pd.DataFrame({\n",
        "    'Id': test_id,\n",
        "    'SalePrice': final_predictions\n",
        "})\n",
        "\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "35czSPLlqo6P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}