{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbdDtyeU2Dn44nXO96KtOj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Oelebrashy/Machine-Learning/blob/main/Housing_Prices.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaagipX90z8b"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the datasets\n",
        "train_path = '/content/drive/My Drive/House Prices-Advanced Regression Techniques/train.csv'\n",
        "test_path = '/content/drive/My Drive/House Prices-Advanced Regression Techniques/test.csv'\n",
        "data_description_path = '/content/drive/My Drive/House Prices-Advanced Regression Techniques/data_description.txt'\n",
        "\n",
        "train = pd.read_csv(train_path)\n",
        "test = pd.read_csv(test_path)\n",
        "\n",
        "# Preserve the target variable 'SalePrice' and the 'Id' column before encoding\n",
        "train_id = train['Id']\n",
        "train_target = train['SalePrice']\n",
        "test_id = test['Id']\n",
        "\n",
        "# Drop 'Id' and 'SalePrice' before handling missing values and encoding\n",
        "train = train.drop(['Id', 'SalePrice'], axis=1)\n",
        "test = test.drop(['Id'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the training dataset\n",
        "print(\"Training Data:\")\n",
        "print(train.head())\n",
        "\n",
        "print(\"\\nTest Data:\")\n",
        "print(test.head())"
      ],
      "metadata": {
        "id": "lto_kYAv2VsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(\"\\nMissing values in training set:\")\n",
        "print(train.isnull().sum()[train.isnull().sum() > 0])\n",
        "\n",
        "print(\"\\nMissing values in test set:\")\n",
        "print(test.isnull().sum()[test.isnull().sum() > 0])"
      ],
      "metadata": {
        "id": "aqzw8EwA2Y36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data description\n",
        "with open(data_description_path, 'r') as file:\n",
        "    data_description = file.read()\n",
        "\n",
        "print(\"\\nData Description:\")\n",
        "print(data_description)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FR9deusp2crN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial data visualization\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(train['SalePrice'], kde=True)\n",
        "plt.title('Distribution of Sale Prices')\n",
        "plt.xlabel('SalePrice')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0YfO6_5h2fPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the data types of each column\n",
        "print(\"\\nData Types in Training Set:\")\n",
        "print(train.dtypes)\n"
      ],
      "metadata": {
        "id": "D9RDAULz2BF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values for categorical features\n",
        "train['Alley'].fillna('None', inplace=True)\n",
        "train['MasVnrType'].fillna('None', inplace=True)\n",
        "train['BsmtQual'].fillna('NA', inplace=True)\n",
        "train['BsmtCond'].fillna('NA', inplace=True)\n",
        "train['BsmtExposure'].fillna('NA', inplace=True)\n",
        "train['BsmtFinType1'].fillna('NA', inplace=True)\n",
        "train['BsmtFinType2'].fillna('NA', inplace=True)\n",
        "train['Electrical'].fillna(train['Electrical'].mode()[0], inplace=True)\n",
        "train['FireplaceQu'].fillna('NA', inplace=True)\n",
        "train['GarageType'].fillna('NA', inplace=True)\n",
        "train['GarageFinish'].fillna('NA', inplace=True)\n",
        "train['GarageQual'].fillna('NA', inplace=True)\n",
        "train['GarageCond'].fillna('NA', inplace=True)\n",
        "train['PoolQC'].fillna('NA', inplace=True)\n",
        "train['Fence'].fillna('NA', inplace=True)\n",
        "train['MiscFeature'].fillna('None', inplace=True)\n",
        "\n",
        "# Fill missing values for numerical features\n",
        "train['LotFrontage'] = train.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
        "train['MasVnrArea'].fillna(0, inplace=True)\n",
        "train['GarageYrBlt'].fillna(train['YearBuilt'], inplace=True)\n",
        "train['BsmtFinSF1'].fillna(0, inplace=True)\n",
        "train['BsmtFinSF2'].fillna(0, inplace=True)\n",
        "train['BsmtUnfSF'].fillna(0, inplace=True)\n",
        "train['TotalBsmtSF'].fillna(0, inplace=True)\n",
        "train['BsmtFullBath'].fillna(0, inplace=True)\n",
        "train['BsmtHalfBath'].fillna(0, inplace=True)\n",
        "train['GarageCars'].fillna(0, inplace=True)\n",
        "train['GarageArea'].fillna(0, inplace=True)\n",
        "\n",
        "# Repeat the same steps for the test set\n",
        "test['Alley'].fillna('None', inplace=True)\n",
        "test['MasVnrType'].fillna('None', inplace=True)\n",
        "test['BsmtQual'].fillna('NA', inplace=True)\n",
        "test['BsmtCond'].fillna('NA', inplace=True)\n",
        "test['BsmtExposure'].fillna('NA', inplace=True)\n",
        "test['BsmtFinType1'].fillna('NA', inplace=True)\n",
        "test['BsmtFinType2'].fillna('NA', inplace=True)\n",
        "test['Electrical'].fillna(test['Electrical'].mode()[0], inplace=True)\n",
        "test['FireplaceQu'].fillna('NA', inplace=True)\n",
        "test['GarageType'].fillna('NA', inplace=True)\n",
        "test['GarageFinish'].fillna('NA', inplace=True)\n",
        "test['GarageQual'].fillna('NA', inplace=True)\n",
        "test['GarageCond'].fillna('NA', inplace=True)\n",
        "test['PoolQC'].fillna('NA', inplace=True)\n",
        "test['Fence'].fillna('NA', inplace=True)\n",
        "test['MiscFeature'].fillna('None', inplace=True)\n",
        "\n",
        "test['LotFrontage'] = test.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
        "test['MasVnrArea'].fillna(0, inplace=True)\n",
        "test['GarageYrBlt'].fillna(test['YearBuilt'], inplace=True)\n",
        "test['BsmtFinSF1'].fillna(0, inplace=True)\n",
        "test['BsmtFinSF2'].fillna(0, inplace=True)\n",
        "test['BsmtUnfSF'].fillna(0, inplace=True)\n",
        "test['TotalBsmtSF'].fillna(0, inplace=True)\n",
        "test['BsmtFullBath'].fillna(0, inplace=True)\n",
        "test['BsmtHalfBath'].fillna(0, inplace=True)\n",
        "test['GarageCars'].fillna(0, inplace=True)\n",
        "test['GarageArea'].fillna(0, inplace=True)\n"
      ],
      "metadata": {
        "id": "Yz-B4Xkv27JA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encoded = pd.get_dummies(train)\n",
        "test_encoded = pd.get_dummies(test)\n",
        "\n",
        "# Align the train and test datasets to have the same columns\n",
        "train_encoded, test_encoded = train_encoded.align(test_encoded, join='inner', axis=1)\n",
        "\n",
        "# Add back the target variable 'SalePrice' to the encoded training set\n",
        "train_encoded['SalePrice'] = train_target\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "corr_matrix = train_encoded.corr()\n",
        "\n",
        "# Sort the correlation values with SalePrice\n",
        "sorted_corr = corr_matrix['SalePrice'].sort_values(ascending=False)\n",
        "print(sorted_corr)"
      ],
      "metadata": {
        "id": "RQFg6luu5CCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting top features based on correlation with SalePrice\n",
        "top_features = ['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF', '1stFlrSF',\n",
        "                'FullBath', 'TotRmsAbvGrd', 'YearBuilt', 'YearRemodAdd']\n",
        "\n",
        "X = train_encoded[top_features]\n",
        "y = train_encoded['SalePrice']\n",
        "\n",
        "# Ensure the test set has the same selected features\n",
        "X_test = test_encoded[top_features]\n"
      ],
      "metadata": {
        "id": "2QhxWS_J5G3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "KHZmKirf9N6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Train a Linear Regression model\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_pred = lin_reg.predict(X_val)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse_lin = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "print(f'RMSE (Linear Regression): {rmse_lin}')\n"
      ],
      "metadata": {
        "id": "ar2T5gCX9Q0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Train a Random Forest model\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_pred_rf = rf.predict(X_val)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse_rf = np.sqrt(mean_squared_error(y_val, y_pred_rf))\n",
        "print(f'RMSE (Random Forest): {rmse_rf}')\n"
      ],
      "metadata": {
        "id": "KRHXY11v9grt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Train a Gradient Boosting model\n",
        "xg_reg = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
        "xg_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_pred_xg = xg_reg.predict(X_val)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse_xg = np.sqrt(mean_squared_error(y_val, y_pred_xg))\n",
        "print(f'RMSE (XGBoost): {rmse_xg}')\n"
      ],
      "metadata": {
        "id": "2xtMfOd99mjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Train a Gradient Boosting model\n",
        "xg_reg = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
        "xg_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_pred_xg = xg_reg.predict(X_val)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse_xg = np.sqrt(mean_squared_error(y_val, y_pred_xg))\n",
        "print(f'RMSE (XGBoost): {rmse_xg}')\n"
      ],
      "metadata": {
        "id": "1409YUPD9sFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "#Hyperparamter Tuning for Gradient Boosting using Grid Search\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.3]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=xgb.XGBRegressor(objective='reg:squarederror'), param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Predict on the validation set\n",
        "y_pred_best = best_model.predict(X_val)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse_best = np.sqrt(mean_squared_error(y_val, y_pred_best))\n",
        "print(f'Best RMSE: {rmse_best}')\n"
      ],
      "metadata": {
        "id": "k9OyxHBB93Cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test dataset using the best model\n",
        "final_predictions = best_model.predict(X_test)\n",
        "\n",
        "# Prepare the submission file\n",
        "submission = pd.DataFrame({\n",
        "    'Id': test_id,\n",
        "    'SalePrice': final_predictions\n",
        "})\n",
        "\n",
        "submission.to_csv('submission.csv', index=False)\n"
      ],
      "metadata": {
        "id": "UGWRPead9usJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}